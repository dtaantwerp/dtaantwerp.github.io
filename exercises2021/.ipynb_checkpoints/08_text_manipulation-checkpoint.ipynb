{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises on String Manipulation\n",
    "\n",
    "Use this [notebook](https://github.com/dtaantwerp/dtaantwerp.github.io/blob/master/notebooks2021/12_Week2_Wednesday_string_text_manipulation.ipynb) for a complete explanation of String Manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Implement a function that repeats text n times\n",
    "\n",
    "Input parameters: text: str, times: int  \n",
    "Output parameters: text: str\n",
    "\n",
    "Format the output text in such a way that given text always starts from a new line.  \n",
    "\n",
    "To-do:\n",
    "1. Define a function with given input and output parameters;\n",
    "2. Concatenate new line character to input text;\n",
    "3. Multiply modified text by a given number of times;  \n",
    " \n",
    "\n",
    "4. Print the function's output for a given 'text' and 'times' variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Falling In Love Again with Python!'\n",
    "times = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(text, times):\n",
    "    text = text+'\\n'\n",
    "    text = text*times\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with Python!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = echo(text, times)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a. Upgrade the previous function to reduce the number of characters in a text after each repetition\n",
    "\n",
    "Input parameters: text: str, times: int, reduction_rate: float   \n",
    "Output parameters: text: str\n",
    "\n",
    "Format the output text in such a way that given text always starts from a new line.  \n",
    "\n",
    "To-do:\n",
    "1. Modify function definition to take as input a new parameter ('reduction_rate');\n",
    "2. Initialize 'new_text' variable that will accumulate reduced texts;\n",
    "3. Implement 'for loop' to iterate over the number of repetitions;\n",
    "4. Calculate the length of text after each reduction (e.g. text lenght=100, reduction_rate=0.7, new length after reduction = 70 (100*0.7);\n",
    "5. Cast the calculated length to an integer;\n",
    "6. Reduce the number of characters to a given length;  \n",
    "7. Add reduced text with a new line character to the variable that accumulates reduced texts; \n",
    "\n",
    "\n",
    "8. Print output of echo function for a given 'text', 'times', and 'reduction_rate' variables.\n",
    "\n",
    "###### Tips\n",
    "###### Useful Python built-in functions:  \n",
    "range(n) - Returns a sequence of numbers for a given n, starting from 0 and incrementing by 1 till n.  \n",
    "https://docs.python.org/3/library/stdtypes.html#range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(text, times, reduction_rate):\n",
    "    new_text = ''\n",
    "    \n",
    "    for n in range(times):\n",
    "        end = len(text)*reduction_rate\n",
    "        end = int(end)\n",
    "        text = text[:end]\n",
    "        new_text+=text+'\\n'\n",
    "        \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Falling In Love Again with Python!'\n",
    "times = 10\n",
    "reduction_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling In Love Again with \n",
      "Falling In Love Again\n",
      "Falling In Love \n",
      "Falling In L\n",
      "Falling I\n",
      "Falling\n",
      "Falli\n",
      "Fall\n",
      "Fal\n",
      "Fa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = echo(text, times, reduction_rate)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b. Upgrade the function from 2a, so that it outputs the full text first and then reduces the text after each repetition\n",
    "\n",
    "Input parameters: text: str, times: int, reduction_rate: float   \n",
    "Output parameters: text: str\n",
    "\n",
    "Format output text in such a way that given text always starts from a new line.  \n",
    "\n",
    "To-do:\n",
    "1. Implement if-else logic to skip a text reduction during the first iteration;    \n",
    "2. Print output of the function for a given 'text', 'times', and 'reduction_rate' variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(text, times, reduction_rate):\n",
    "    new_text = ''\n",
    "    for n in range(times):\n",
    "        if n == 0:\n",
    "            new_text+=text+'\\n'\n",
    "        else:\n",
    "            end = int(len(text)*reduction_rate)\n",
    "            text = text[:end]\n",
    "            new_text +=text+'\\n'\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Falling In Love Again with Python!'\n",
    "times = 10\n",
    "reduction_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling In Love Again with Python!\n",
      "Falling In Love Again with \n",
      "Falling In Love Again\n",
      "Falling In Love \n",
      "Falling In L\n",
      "Falling I\n",
      "Falling\n",
      "Falli\n",
      "Fall\n",
      "Fal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = echo(text, times, reduction_rate)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Warm-up excercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Implement a function that extracts Proper Nouns (Named Entities) in texts.\n",
    "##### 3a. Warm-up \n",
    "\n",
    "###### Useful Python built-in methods:  \n",
    "list.append(x) - Add an item to the end of the list;   \n",
    "list.extend(iterable) - Extend the list by appending all the items from the iterable;  \n",
    "https://docs.python.org/3/tutorial/datastructures.html\n",
    "\n",
    "str.split() - Return a list of the words in the string, using sep as the delimiter string;  \n",
    "https://docs.python.org/3/library/stdtypes.html#str.split\n",
    "\n",
    "str.lower() - Return a copy of the string with all the cased characters converted to lowercase;  \n",
    "https://docs.python.org/3/library/stdtypes.html#str.lower  \n",
    "\n",
    "str.islower() - Return True if all cased characters in the string are lowercase and there is at least one cased character, False otherwise;\n",
    "https://docs.python.org/3/library/stdtypes.html#str.islower\n",
    "\n",
    "str.isdigit() - Return True if all characters in the string are digits and there is at least one character, False otherwise.\n",
    "https://docs.python.org/3/library/stdtypes.html#str.isdigit\n",
    "\n",
    "sorted() - Return a new sorted list from the items in iterable;  \n",
    "https://docs.python.org/3/library/functions.html#sorted  \n",
    "\n",
    "\n",
    "1.1. Add an element to a list. E.g. [1,2,3,4], 5 --> [1,2,3,4,5];    \n",
    "1.2. Print the modified list;   \n",
    "\n",
    "2.1. Create a list words from a given text. E.g. 'The Sun Always Shines on T.V.' --> ['The', 'Sun', 'Always', 'Shines', 'on', 'T.V.'];  \n",
    "2.2. Print the list of words; \n",
    "\n",
    "3.1. Find a lowercase word in list of words; ['The', 'Sun', 'Always', 'Shines', 'on', 'T.V.'] --> 'on';  \n",
    "3.2. Print the word;\n",
    "\n",
    "4.1. Lowercase a given text. E.g. 'The Sun Always Shines on T.V.' --> 'the sun always shines on t.v.';  \n",
    "4.2. Print the lowercased text;  \n",
    "\n",
    "5.1. Sort a list. E.g. [1,3,5,2,4] --> [1,2,3,4,5], ['c','b','a'] --> ['a','b','c'];  \n",
    "5.1. Print the sorted list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "l = [1,2,3,4]\n",
    "el = 5\n",
    "l.append(el)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Sun', 'Always', 'Shines', 'on', 'T.V.']\n"
     ]
    }
   ],
   "source": [
    "s = 'The Sun Always Shines on T.V.'\n",
    "s = s.split()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on\n"
     ]
    }
   ],
   "source": [
    "s = 'The Sun Always Shines on T.V.'.split()\n",
    "for w in s:\n",
    "    if w.islower():\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sun always shines on t.v.\n"
     ]
    }
   ],
   "source": [
    "s = 'The Sun Always Shines on T.V.'\n",
    "s = s.lower()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "l = [1,3,5,2,4]\n",
    "l = sorted(l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "l = ['c', 'b', 'a']\n",
    "l = sorted(l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3b. Implement a function that extracts Proper Nouns (Named Entities) in texts.\n",
    "Let's assume that all capitalized words are proper nouns.\n",
    "\n",
    "Input parameters: texts: list  \n",
    "Output parameters: entities: list \n",
    "\n",
    "To-do:  \n",
    "1.1. Define a helper function that takes a text and returns a list of capitalized words;  \n",
    "1.2. Initialize 'cap_words' variable to accumulate capitalized words;   \n",
    "1.3. Break text into chunks separating it by whitespace character;  \n",
    "1.4. Iterate over tokens to identify tokens that are not lowercased;  \n",
    "1.5. Add selected tokens to 'cap_words' variable;  \n",
    "\n",
    "2.1. Define a function with given input and output parameters;  \n",
    "2.2. Initialize 'entities' variable to accumulate entities;   \n",
    "2.3. Iterate of over given texts;  \n",
    "2.4. Apply the helper function ('extract_cap_words') to each text;  \n",
    "2.4. Add entities to entities variable;   \n",
    "\n",
    "3.1. Execute the implemented function ('ner') for a given input;  \n",
    "3.2. Print entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Apparently while learning English, GPT-2 also accidentally picked up some JavaScript\",\n",
    "         \"I don't think anyone's really concerned about GPT-2 pioneering a new form of hate speech...but customized hate speech of infinite length, diversity for getting through bot filters/human detection of it being from 1 source?\",\n",
    "         \"This debate isn't *just* about GPT-2 and how risky it is today, but how to proceed given real tradeoffs (e.g. between showing people what the risks are by letting them use it, vs. limiting misuse), and we should have that convo before the next phase of LMs are widely deployed.\",\n",
    "         \"Fears of OpenAI's super-trolling artificial intelligence are overblown\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cap_words(text):\n",
    "    cap_words = []\n",
    "    text = text.split()\n",
    "    \n",
    "    for token in text:\n",
    "        if not token.islower():\n",
    "            cap_words.append(token)\n",
    "            \n",
    "    return cap_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(texts):\n",
    "    entities = []\n",
    "    \n",
    "    for doc in texts:\n",
    "        doc_entities = extract_cap_words(doc)\n",
    "        entities+=doc_entities\n",
    "        \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apparently', 'English,', 'GPT-2', 'JavaScript', 'I', 'GPT-2', '1', 'This', 'GPT-2', 'LMs', 'Fears', \"OpenAI's\"]\n"
     ]
    }
   ],
   "source": [
    "entities = ner(texts)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3b. Improve the previous function by filtering out punctuation, stopwords, and the first word in texts.\n",
    "\n",
    "Input parameters: texts: list, punctuation: str, stopwords: list  \n",
    "Output parameters: entities: dict\n",
    "        \n",
    "Instead of returning a raw list of entities, return a count of unique entities. \n",
    "\n",
    "To-do:  \n",
    "1.1. Define 'clean_text' function that takes in 'text', 'punctuation', and 'stopwords' parameters. Function filters punctuation and stopwords from a text. It returns a list of tokens;    \n",
    "1.2. Iterate over punctuation and remove it from a text;  \n",
    "1.3. Break text into chunks separating it by whitespace character;  \n",
    "1.4. Iterate over tokens. Skip the first token (i.e., make a naive assumption that Named Entities are not among first words). Filter out tokens that belong to stopwords (lowercase tokens);  \n",
    "\n",
    "2.1. Modify extract_cap_words function to take as input list of tokens;  \n",
    "2.2. Exclude tokens that are digits;  \n",
    "\n",
    "3.1. Modify ner function to clean text from punctuation and stopwords;  \n",
    "3.2. Calculate the frequency of each entity;\n",
    "\n",
    "4.1. Execute ner function for a given input;  \n",
    "4.2. Print the quantities sorted from larger to smaller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '''!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, punctuation, stopwords): \n",
    "    for char in punctuation:\n",
    "        text = text.replace(char, '')\n",
    "    \n",
    "    text = text.split()\n",
    "    tokens = []\n",
    "    \n",
    "    for token in text[1:]:\n",
    "        if token.lower() not in stopwords:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cap_words(tokens):\n",
    "    cap_words = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if not token.islower() and not token.isdigit():\n",
    "            cap_words.append(token)\n",
    "            \n",
    "    return cap_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(texts, punctuation, stopwords):\n",
    "    entities = []\n",
    "    \n",
    "    for doc in texts:\n",
    "        doc_tokens = clean_text(doc, punctuation, stopwords)\n",
    "        doc_entities = extract_cap_words(doc_tokens)\n",
    "        entities+=doc_entities\n",
    "    entities = Counter(entities)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GPT2', 3), ('English', 1), ('JavaScript', 1), ('LMs', 1), ('OpenAIs', 1)]\n"
     ]
    }
   ],
   "source": [
    "entities = ner(texts, punctuation, stopwords)\n",
    "print(entities.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Decipherment of secret script (advanced)\n",
    "##### 4a. Warm-up  \n",
    "\n",
    "###### Tips\n",
    "###### Useful Python built-in functions and methods:\n",
    "zip(*iterables) - Make an iterator that aggregates elements from each of the iterables.\n",
    "https://docs.python.org/3/library/functions.html#zip\n",
    "\n",
    "It is possible to create a dictionary from two lists using Dictionary constructor and built-in Python function 'zip'. \n",
    "\n",
    "1.1 Rotate a given list by one element. E.g. [1,2,3,4] --> [2,3,4,1];  \n",
    "1.2. Print the modified list.  \n",
    "\n",
    "2.1. Create a dictionary from two lists. E.g. ['a','b,'c','d'] and [1,2,3,4] --> {'a':1, 'b':2, 'c':3, 'd': 4};  \n",
    "2.2. Print the constructed dictionary;  \n",
    "\n",
    "3.1. Create a dictionary form two lists using zip();  \n",
    "3.2. Print the constructed dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "l = [1,2,3,4,5]\n",
    "l = l[1:]+l[0:1]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1], 'b': [2], 'c': [3], 'd': [4]}\n"
     ]
    }
   ],
   "source": [
    "l1 = ['a','b','c','d']\n",
    "l2 = [1,2,3,4]\n",
    "d = dict()\n",
    "if len(l1) == len(l2):\n",
    "    for i in range(len(l1)):\n",
    "        d[l1[i]] = [l2[i]]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4}\n"
     ]
    }
   ],
   "source": [
    "l1 = ['a','b','c','d']\n",
    "l2 = [1,2,3,4]\n",
    "d = dict(zip(l1,l2))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4b. Decipherment of secret script (advanced)\n",
    "\n",
    "You received an encoded message and keys (cipher: Python dictionary). Accidentally, the keys in the cipher were shifted, but the order is still correct. Implement a function that finds the right combination of keys to encode given text. You received the hint that the text contains a specific work (see hint).\n",
    "\n",
    "Implement a function that finds the correct combination of keys and decodes the text.\n",
    "\n",
    "Input parameters: encoded_text: string, broken_codes: dict, hint: str  \n",
    "Output parameters: decoded_text: str\n",
    "        \n",
    "\n",
    "To-do:  \n",
    "Implement the helper function 'convert_text' that converts a text based on the cipher.  \n",
    "\n",
    "1.1. Define function 'convert_text' that as input takes text: str and codes: dict and returns decoded text;  \n",
    "1.2. Convert string to list of characters;  \n",
    "1.3. Iterate over characters and change characters to the corresponding character in codes (e.g., code {'X':'z'}, so X-->z);    \n",
    "1.4. Convert a decoded list of characters to a string.     \n",
    "\n",
    "Implement the 'crack_code' function that finds the correct codes.  \n",
    "\n",
    "2.1. Define a function ('crack_code') that takes encoded_text: string, broken_codes: dict, hint: str and returns decoded_text: str;  \n",
    "2.2. Obtain a list of alphabetic characters from wrong codes;    \n",
    "2.3. Obtain a list of corresponding codes from wrong codes;    \n",
    "2.4. In a loop, shift codes by one element;  \n",
    "2.5. Construct a new cipher based on shifted codes;  \n",
    "2.6. Decode text with new cipher;  \n",
    "2.7. Check whether hint word is in the converted text;  \n",
    "2.8. Stop iterating when the correct cipher is found;  \n",
    "2.9. Return the decoded text;  \n",
    "\n",
    "2.10. Print the decoded text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = 'dunSSBmS ueFS PLPCm, PLPCm uBcCmS mBuo, mBuo umeSOCS knRLmI, knRLmI PBnSBtS dPBuo, dPBuo SWLSOCS SunSSBmS, SunSSBmS ICuLPnFLFCS knRLmI, knRLmI CLFS PLPCm, PLPCm InSPmBcCS dPBuo, dPBuo cLPBmnRCS mBuo, LtI LS nF LkELTS OLS, mBuo umeSOCS SunSSBmS.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_codes = {'A': 'A', 'Q': 'B', 'J': 'C', 'd': 'D', 'X': 'E', 'j': 'F', 'G': 'G', 'g': 'H', 'M': 'I', 'q': 'J',\n",
    "                'y': 'K', 'L': 'L', 'H': 'M', 'u': 'N', 'I': 'O', 'C': 'P', 'U': 'Q', 'D': 'R', 'O': 'S', 'n': 'T',\n",
    "                'i': 'U', 'o': 'V', 'k': 'W', 'W': 'X', 't': 'Y', 'B': 'Z', 'P': 'a', 'r': 'b', 'm': 'c', 'S': 'd',\n",
    "                'F': 'e', 'e': 'f', 'c': 'g', 'E': 'h', 'f': 'i', 'T': 'j', 'R': 'k', 'z': 'l', 'b': 'm', 'V': 'n',\n",
    "                'x': 'o', 's': 'p', 'l': 'q', 'h': 'r', 'N': 's', 'p': 't', 'v': 'u', 'Z': 'v', 'Y': 'w', 'w': 'x',\n",
    "                'a': 'y', 'K': 'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = 'Spock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text(text, keys):\n",
    "    text = list(text)\n",
    "    for i in range(len(text)):\n",
    "        if text[i] in keys:\n",
    "            text[i] = keys[text[i]]\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crack_code(text, broken_codes, hint):\n",
    "    abc = list(broken_codes.values())\n",
    "    codes = list(broken_codes.keys())\n",
    "    \n",
    "    for i in range(len(codes)):\n",
    "        codes = codes[1:]+codes[0:1]\n",
    "        new_codes = dict(zip(codes, abc))\n",
    "        decoded_text = convert_text(text, new_codes)\n",
    "        if hint in decoded_text:\n",
    "            break\n",
    "            \n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = crack_code(encoded_text, broken_codes, hint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scissors cuts paper, paper covers rock, rock crushes lizard, lizard poisons Spock, Spock smashes scissors, scissors decapitates lizard, lizard eats paper, paper disproves Spock, Spock vaporizes rock, and as it always has, rock crushes scissors.\n"
     ]
    }
   ],
   "source": [
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4a. Simple semantic Triples extractor\n",
    "\n",
    "Implement a function that extracts semantic triples (Subject, Predicate, Object) from text based on some heuristics.\n",
    "\n",
    "Input parameters: text: str  \n",
    "Output parameters: triples: list\n",
    "        \n",
    "\n",
    "To-do:  \n",
    "Implement the helper function 'clean_text' that lowercases text and removes punctuation.   \n",
    "\n",
    "1.1. Define function 'clean_text' that as input takes text: str and punctuation: str and returns cleaned text;    \n",
    "1.2. Iterate over punctuation and remove it from a text;  \n",
    "1.3. Lowercase text;   \n",
    "1.4. Return cleaned text;\n",
    "\n",
    "Implement an 'extract_triples' function that extracts semantic triples.   \n",
    "\n",
    "2.1. Define 'extract_triples' function that takes text: str and returns triples: list;   \n",
    "2.2. Divide  text based on 'comma' character;     \n",
    "2.3. Remove extra white spaces from obtained chunks of text;  \n",
    "2.4. Divide chunks based on 'whitespace' character;  \n",
    "2.5. Filter chunks that have three elements (triples);  \n",
    "2.6. Clean each element of triple applying the 'clean_text' function;  \n",
    "2.7. Return the list of triples;  \n",
    "\n",
    "2.8. Print the list of triples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, punctuation):\n",
    "    for char in punctuation:\n",
    "        text = text.replace(char, '')\n",
    "        text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples(text):\n",
    "    chunks = text.split(',')\n",
    "    clean_chunks = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        clean_chunks.append(chunk.strip())\n",
    "    \n",
    "    triples = []\n",
    "    \n",
    "    for chunk in clean_chunks:\n",
    "        triple = chunk.split()\n",
    "        \n",
    "        if len(triple) == 3:\n",
    "            triples.append(triple)\n",
    "        \n",
    "    for triple in triples:\n",
    "        for i, el in enumerate(triple):\n",
    "            triple[i] = clean_text(triple[i], punctuation)\n",
    "            \n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['scissors', 'cuts', 'paper'], ['paper', 'covers', 'rock'], ['rock', 'crushes', 'lizard'], ['lizard', 'poisons', 'spock'], ['spock', 'smashes', 'scissors'], ['scissors', 'decapitates', 'lizard'], ['lizard', 'eats', 'paper'], ['paper', 'disproves', 'spock'], ['spock', 'vaporizes', 'rock'], ['rock', 'crushes', 'scissors']]\n"
     ]
    }
   ],
   "source": [
    "triples = extract_triples(decoded_text)\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4b. Subject, Predicate, Object (SPO) extractor (Optional)\n",
    "Impelment a function that genrates a list of unique Subject, Predicate, Object (SPO) from a list of triples.\n",
    "\n",
    "Input parameters: triples: list  \n",
    "Output parameters: spo: list\n",
    "        \n",
    "\n",
    "To-do:  \n",
    "Implement a function that creates lists of unique subjects, predicates, and objects.\n",
    "\n",
    "3.1. Define 'extract_spo' function that takes triples: list and returns subjects: list, objects: list, predicates: list;  \n",
    "3.2. Initiate subjects, objects, predicates sets;  \n",
    "3.3. Iterate over a list of triples;  \n",
    "3.4. Add the corresponding elements of triples to the sets of subjects, predicates, and objects;  \n",
    "3.5. Sort the list of subjects, predicates, and objects;  \n",
    "3.6. Return the lists of subjects, predicates, and objects;  \n",
    "\n",
    "3.7. Print the lists of subjects, predicates, and objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spo(triples):\n",
    "    subjects = set()\n",
    "    objects = set()\n",
    "    predicates = set()\n",
    "    \n",
    "    for triple in triples:\n",
    "        subjects.add(triple[0])\n",
    "        objects.add(triple[2])\n",
    "        predicates.add(triple[1])\n",
    "        \n",
    "    subjects = sorted(subjects)\n",
    "    objects = sorted(objects)\n",
    "    predicates = sorted(predicates)\n",
    "    \n",
    "    return subjects, predicates, objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lizard', 'paper', 'rock', 'scissors', 'spock'] ['covers', 'crushes', 'cuts', 'decapitates', 'disproves', 'eats', 'poisons', 'smashes', 'vaporizes'] ['lizard', 'paper', 'rock', 'scissors', 'spock']\n"
     ]
    }
   ],
   "source": [
    "subjects, predicates, objects = extract_spo(triples)\n",
    "print(subjects, predicates, objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
